from sqlalchemy import create_engine, Column, String, Boolean, Integer, Float, Numeric, MetaData, Table, type_coerce, ForeignKey
from sqlalchemy.orm import mapper, create_session, relationship
from sqlalchemy.ext.declarative import declarative_base
import sqlalchemy.types as types
import re
import os
import glob
import numpy as np

# 20200929: added code to handle new files since 2018
# 20181120: some modifications compared to nutrient version because some files (9xxx.ctd) are upcasts associated with downcasts that are missing data
# in the case where both up and down have data at a depth, choose down (supposedly more accurate). Set the other 'include'=False.

def main():

    basepath='/ocean/shared/SalishSeaCastData/DFO/CTD/'
    basedir=basepath + 'req20181116/'
    dbname='DFO_CTD'
    # if more paths added later (additional data requests) see createDBfromDFO_OPDB.py for how to add
    fout=open(basepath+'createDBfromDFO_CTD_log.txt','w')
    ferr=open(basepath+'createDBfromDFO_CTD_errors.txt','w')
    fout.write('Files processed:\n')

    dirs0=[os.path.join(basepath,x) for x in os.listdir(basepath) if (os.path.isdir(basepath+x) and not re.match('^\.', x))]
    dirs1=list()
    for ireq in dirs0:
        dirs1=dirs1+[os.path.join(ireq,x) for x in os.listdir(ireq) \
                     if (os.path.isdir(os.path.join(ireq,x)) and not re.match('^\.', x))]
    dirs1.sort()
    # create full list of filenames
    filenames1=list()
    bnamesAll=list() 
    for cdirpath in dirs1:
        filenames1=filenames1+[os.path.join(cdirpath,f) for f in os.listdir(cdirpath) \
                               if ((f not in bnamesAll) and (not re.match('.*jpg$',f)))]
        bnamesAll=bnamesAll+[f for f in os.listdir(cdirpath)]
        # left over from nutrients version where multiple requests led to overlap; retain for future use
    filenames1.sort()
    filenames=filenames1 #contains full paths

    # create set of variable names for Obs table: see develope_createDBfromDFO_OPDB.ipynb
    choosevars={'Conductivity', 'Conductance_Specific', 'PAR1', 'Pressure', 'Temperature', 'Salinity_T0_C0', 
                'PAR', 'Salinity', 'PAR_Reference', 'Temperature_Primary', 'Fluorescence_URU_Seapoint', 
                'Conductivity_Primary', 'pH_SBE_Nominal', 'Number_of_bin_records', 'Density', 
                'Oxygen_Dissolved_SBE', 'Temperature_Secondary', 'Fluorescence_URU_Wetlabs', 
                'Conductivity_Secondary', 'Salinity_T1_C1', 'PAR_1', 'Oxygen_Dissolved_SBE_1', 'Depth', 
                'Speed_Sound', 'Transmissivity'}
    varlistu=choosevars | {x+'_units' for x in choosevars if not re.search('Flag', x)}

    # create database and prepare tables
    engine = create_engine('sqlite:///' + basepath + dbname + '.sqlite')
    Base=declarative_base()

    # create classes for custom data types
    class forceNumeric(types.TypeDecorator):

        impl = types.Float
        def process_bind_param(self, value, dialect):
            try:
                int(float(value))
                if (int(float(value))==-99 or int(10*float(value))==-99):
                    value=None
            except:
                value = None
            if (str(value).startswith('-99') or str(value).startswith('9999') or str(value)=='0.0000'):
                value = None
            return value

    class forceInt(types.TypeDecorator):

        impl = types.Integer
        def process_bind_param(self, value, dialect):
            try:
                int(value)
                if int(value)==-99:
                    value=None
            except:
                value = None
            if (str(value).startswith('-99') or str(value).startswith('9999')):
                value = None
            return value

    # create function that returns datatype for a given field name
    def coltype(ikey):
        typedict = {
            'Date': String(),
            'Sample_Method': String(),
            'Station': String(),
            'Time': String(),
            'Time_of_Obs.': String(),
        }
        for varn in varlistu:
            if (re.search('Flag', varn) or varn in varlistu-choosevars):
                typedict[varn]=String()
        return typedict.get(ikey, forceNumeric())

    # define Table Classes:
    class StationTBL(Base):
        __table__=Table('StationTBL', Base.metadata,
                    Column('ID', Integer, primary_key=True),
                    Column('STATION', String),
                    Column('EVENT_NUMBER', String),
                    Column('LATITUDE', String),
                    Column('Lat', forceNumeric),
                    Column('LONGITUDE', String),
                    Column('Lon', forceNumeric),
                    Column('WATER_DEPTH', forceNumeric),
                    Column('WDIR', forceNumeric),
                    Column('WSPD', forceNumeric),
                    Column('START_TIME', String),
                    Column('StartDay',forceNumeric),
                    Column('StartMonth',forceNumeric),
                    Column('StartYear',forceNumeric),
                    Column('StartHour',forceNumeric),
                    Column('StartTimeZone',String),
                    Column('DATA_DESCRIPTION', String),
                    Column('MISSION', String),
                    Column('AGENCY', String),
                    Column('COUNTRY', String),
                    Column('PROJECT', String),
                    Column('SCIENTIST', String),
                    Column('PLATFORM', String),
                    Column('TYPE', String),
                    Column('MODEL', String),
                    Column('SERIAL', String),
                    Column('XmisPathLen', forceNumeric),
                    Column('Include', Boolean, default=True),
                    Column('sourceFile', String))

    class ObsTBL(Base):
        __table__=Table('ObsTBL', Base.metadata,
                        Column('ID', Integer, primary_key=True),
                        Column('sourceFile', String),
                        Column('Include', Boolean, default=True),
                        Column('StationTBLID', forceInt, ForeignKey('StationTBL.ID')),
                        *(Column(cname, coltype(cname)) for cname in varlistu))
        station=relationship(StationTBL, primaryjoin=__table__.c.StationTBLID == StationTBL.ID)

    Base.metadata.create_all(engine)
    session = create_session(bind = engine, autocommit = False, autoflush = True)

    stationNo=0
    for ifile in filenames:
        stationNo+=1
        sourceFile=re.search(basepath+'(.*)', ifile).group(1)
        fout.write(sourceFile+'\n')
        varNames={}
        varLens={}
        varUnits={}
        stationData={}
        stationData['ID']=stationNo
        stationData['sourceFile']=sourceFile
        with open(ifile, 'rt', encoding = "ISO-8859-1") as f:
            infile=False
            invars=False
            indetail=False
            inadmin=False
            inloc=False
            ininst=False
            incom=False
            indata=False
            detformat=False
            for line in f:
                if infile:
                    if re.match('\s*\$', line) or len(line)==0:
                        infile=False
                    else:
                        splitline=re.split('\s*\:\s*',line.strip(), maxsplit=1)
                        if re.match('START TIME',splitline[0]):
                            stationData['START_TIME']=splitline[1]
                            splits=re.split('\s* \s*',splitline[1])
                            stationData['StartTimeZone']=splits[0]
                            date=splits[1]
                            time=splits[2]
                            stationData['StartYear']=date[0:4]
                            stationData['StartMonth']=date[5:7]
                            stationData['StartDay']=date[8:]
                            splitTime=re.split('\:',time)
                            stationData['StartHour']=float(splitTime[0])+float(splitTime[1])/60.0+float(splitTime[2])/3600.0
                        elif re.match('DATA DESCRIPTION',splitline[0]):
                            stationData['DATA_DESCRIPTION']=splitline[1]
                if invars:
                    if re.search('\$END', line):
                        invars=False
                    else:
                        test=re.findall("'.*?'",line) # (.*? matches anything but chooses min len match - not greedy)
                        for expr in test:
                            line=re.sub(re.escape(expr),re.sub(' ','_',expr),line) # remove spaces from items in quotes
                        splitline=re.split('\s* \s*',line.strip())
                        if re.match('[0-9]', splitline[0]):
                            varnum=int(splitline[0])
                            cvar=splitline[1]
                            cvar = re.sub('(?<=[0-9])*\.(?=[0-9])','point',cvar) # decimal points -> point
                            cvar = re.sub('\-','',cvar) # remove - from column names
                            cvar = re.sub('\:','_',cvar) # replace : with _
                            cvar = re.sub('\>','gt',cvar) # replace > with gt
                            cvar = re.sub('\<','lt',cvar) # replace < with lt
                            cvar = re.sub('(\'|\.)','',cvar) # remove special characters (' and .)
                            cunits = splitline[2].strip()
                            cvarbase=cvar
                            xx=1
                            while cvar in varNames.values():
                                cvar=cvarbase+'_'+str(xx)
                                xx=xx+1
                            varNames[varnum]=cvar
                            varUnits[varnum]=cunits
                elif indetail:
                    detcount+=1
                    if re.search('\$END', line):
                        indetail=False
                    elif (detcount==1 and re.match('\s*\!\s*No\s*Pad\s*Start\s*Width', line)):
                        detformat=True
                    else:
                        if (detformat and not re.match('\s*\!',line)):
                            test=re.findall("'.*?'",line) # (.*? matches anything but chooses min len match - not greedy)
                            for expr in test:
                                line=re.sub(re.escape(expr),re.sub(' ','_',expr),line) # remove spaces from items in quotes
                            splitline=re.split('\s* \s*',line.strip())
                            varnum=int(splitline[0])
                            try:
                                varwid=int(splitline[3])
                            except:
                                detformat=False
                            varLens[varnum]=varwid
                elif inadmin:
                    if len(line)==0:
                        inadmin=False
                    else:
                        splitline=re.split('\s*\:\s*',line.strip(), maxsplit=1)
                        if re.match('MISSION',splitline[0]):
                            stationData['MISSION']=splitline[1]
                        elif re.match('AGENCY',splitline[0]):
                            stationData['AGENCY']=splitline[1]
                        elif re.match('COUNTRY',splitline[0]):
                            stationData['COUNTRY']=splitline[1]
                        elif re.match('PROJECT',splitline[0]):
                            stationData['PROJECT']=splitline[1]
                        elif re.match('SCIENTIST',splitline[0]):
                            stationData['SCIENTIST']=splitline[1]
                        elif re.match('PLATFORM',splitline[0]):
                            stationData['PLATFORM']=splitline[1]
                elif inloc:
                    if len(line)==0:
                        inloc=False
                    else:
                        splitline=re.split('\s*\:\s*',line.strip(), maxsplit=1)
                        if re.match('STATION',splitline[0]):
                            try:
                                stationData['STATION']=splitline[1]
                            except:
                                print(line)
                                return()
                        elif re.match('EVENT NUMBER',splitline[0]):
                            stationData['EVENT_NUMBER']=splitline[1]
                        elif re.match('LATITUDE',splitline[0]):
                            stationData['LATITUDE']=splitline[1]
                            latparts=re.split('\s* \s*', splitline[1])
                            signdict={'N':1,'E':1,'S':-1,'W':-1}
                            staLat=signdict[latparts[2]]*(float(latparts[0])+float(latparts[1])/60.0)
                            stationData['Lat']=staLat
                        elif re.match('LONGITUDE',splitline[0]):
                            stationData['LONGITUDE']=splitline[1]
                            lonparts=re.split('\s* \s*', splitline[1])
                            signdict={'N':1,'E':1,'S':-1,'W':-1}
                            staLon=signdict[lonparts[2]]*(float(lonparts[0])+float(lonparts[1])/60.0)
                            stationData['Lon']=staLon
                        elif re.match('WATER DEPTH',splitline[0]):
                            stationData['WATER_DEPTH']=delist(splitline[1])
                        elif re.match('WDIR',splitline[0]):
                            stationData['WDIR']=re.split('\s* \s*',splitline[1])[0]
                        elif re.match('WSPD',splitline[0]):
                            stationData['WSPD']=re.split('\s* \s*',splitline[1])[0]
                elif ininst:
                    if len(line)==0:
                        ininst=False
                    else:
                        splitline=re.split('\s*\:\s*',line.strip(), maxsplit=1)
                        if re.match('TYPE',splitline[0]):
                            stationData['TYPE']=splitline[1]
                        elif re.match('MODEL',splitline[0]):
                            stationData['MODEL']=splitline[1]
                        elif re.match('SERIAL',splitline[0]):
                            stationData['SERIAL']=splitline[1]
                elif incom:
                    pathlen=re.search('(?<=PathLength>).*(?=</PathLength)',line)
                    if pathlen:
                        stationData['XmisPathLen']=pathlen[0]
                elif (indata and len(line)!=0 and not re.match('\s*\!',line)):
                    if detformat:
                        varVals={}
                        istart=0
                        for ii in range(1,1+max(varNames.keys())):
                            varVal=line[istart:(istart+varLens[ii])]
                            istart+=varLens[ii]
                            if varNames[ii] in varlistu:
                                varVals[varNames[ii]]=varVal.strip()
                            if varNames[ii]+'_units' in varlistu:
                                varVals[varNames[ii]+'_units']=varUnits[ii]
                        varVals['StationTBLID']=stationNo
                        varVals['sourceFile']=sourceFile
                        #SEND TO DATABASE
                        session.execute(ObsTBL.__table__.insert().values(**varVals))
                    else:
                        varVals={}
                        splitline=re.split('\s*\ \s*',line.strip())
                        if len(splitline)==max(varNames.keys()):
                            for ii in range(1,1+max(varNames.keys())):
                                if varNames[ii] in varlistu:
                                    varVals[varNames[ii]]=splitline[ii-1].strip()
                                if varNames[ii]+'_units' in varlistu:
                                    varVals[varNames[ii]+'_units']=varUnits[ii]
                            varVals['StationTBLID']=stationNo
                            varVals['sourceFile']=sourceFile
                            #SEND TO DATABASE
                            session.execute(ObsTBL.__table__.insert().values(**varVals))
                        else:
                            ferr.write('ERROR: filename:'+sourceFile+' line:'+line)
                if re.match('![- ]*$',line):
                    tem=re.search('(?<=\!)[- ]*$',line)
                    splitline=re.split(r'\s',tem.group(0))
                    for ii in range(1, 1+len(splitline)):
                        varLens[ii]=len(splitline[ii-1])+1
                        detformat=True
                if re.search('\*FILE', line):
                    infile=True
                if re.search('\$TABLE\: CHANNELS', line):
                    invars=True
                if re.search('\$TABLE\: CHANNEL DETAIL', line):
                    indetail=True
                    detcount=0
                if re.search('\*ADMINISTRATION', line):
                    inadmin=True
                if re.search('\*LOCATION', line):
                    inloc=True
                    inadmin=False
                if re.search('\*INSTRUMENT', line):
                    ininst=True
                    inloc=False
                if re.search('\*COMMENTS', line):
                    incom=True
                    ininst=False
                if re.search('\*END OF HEADER', line):
                    indata=True
                    ininst=False
                if re.search('\$END',line):
                    inloc=False
                    ininst=False
                    incom=False
                    indetail=False
                    inadmin=False
            # SEND TO DATABASE (at file level)
            session.execute(StationTBL.__table__.insert().values(**stationData))
    session.commit()
    engine.dispose()
    fout.close()
    ferr.close()
    return

def delist(el):
    sh=np.shape(el)
    if len(sh)==0:
        iel=el
    elif (len(sh)==1) and (sh[0]==1):
        iel= el[0]
    else:
        raise Exception('item passed to delist was not a single value or a single value array; it was: {}'.format(el))
    return iel

if __name__== "__main__":
    main()
